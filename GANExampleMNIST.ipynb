{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Introduction\n",
    "#### The notebook presents a simple bare-minimum example of Generative Adverserial Network (or GAN). \n",
    "\n",
    "Note: The focus is on readability rather than functionality. None of the design choices: network, parameters, or training approach may be optimal. Making this work on larger datasets or more complicated images may require changes. \n",
    "\n",
    "## Goal\n",
    "We want to learn an image generator network _G_. It takes a vector of random numbers and spits out an image. In this specific example, we want to generate simple (28x28 pixel) images of handwritten digits. The GAN framework allows us to learn the network G using another network which concurrently learns to distinguish between a real/fake image, called a disciminator network D. They work as adversaries to train each other. Hence, the name Generative Adversearial Networks.\n",
    "\n",
    "<img src=\"./imgs/GD.png\" width=\"700\">\n",
    "\n",
    "\n",
    "## Training \n",
    "In each training iteration there are two steps. Step 1 updates the parameters of D using the real images and the images generated from G. And, step 2 updates the parameters of G using the feedback from the output of D. This will become more concrete using the example below.\n",
    "<img src=\"./imgs/LearningGAN.png\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ./data\n",
      "    Transforms (if any): ToTensor()\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "print(mnist_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples from MNIST dataset.\n",
      "Image size: 28x28\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size = 10, shuffle= True)\n",
    "\n",
    "# Get a sample batch.\n",
    "it = iter(data_loader)\n",
    "images, _ = it.next()\n",
    "\n",
    "# Get an example batch.\n",
    "disp_img = images.squeeze().numpy()\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(20, 2))  \n",
    "\n",
    "# Display.\n",
    "print(\"Samples from MNIST dataset.\")\n",
    "print(\"Image size: {}x{}\".format(disp_img.shape[1], disp_img.shape[2]))\n",
    "for ii in range(disp_img.shape[0]):\n",
    "    fig.add_subplot(1, 10, ii+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.squeeze(disp_img[ii, :, :]), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define a Generator (G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator architecture\n",
    "<img src=\"./imgs/networkG.png\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, 4*4*128)\n",
    "        self.deconv1 = nn.Sequential(nn.ConvTranspose2d(128, 64, 3, stride = 2, padding = 1),\n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.ReLU())\n",
    "        self.deconv2 = nn.Sequential(nn.ConvTranspose2d(64, 32, 4, stride = 2, padding = 1),\n",
    "                                     nn.BatchNorm2d(32),\n",
    "                                     nn.ReLU())\n",
    "        self.deconv3 = nn.Sequential(nn.ConvTranspose2d(32, 1, 4, stride = 2, padding = 1),\n",
    "                                     nn.Tanh())\n",
    "                       \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.shape[0], 128, 4, 4)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.deconv3(x)\n",
    "        return x\n",
    "    \n",
    "'''\n",
    "Bring the Generator output from [-1, +1] -> [0, 1]\n",
    "'''\n",
    "def out2img(x):\n",
    "    return (x + 1.0)/2.0\n",
    "\n",
    "'''\n",
    "Preprocess the real image to input to the discriminator [-1, +1]\n",
    "'''\n",
    "def img2inp(x):\n",
    "    return (x - 0.5)*2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a sample image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 28x28\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_size = 100 # Size of the random input vector\n",
    "G = Generator(z_size)\n",
    "\n",
    "# Generate a random vector and pass it through the generator.\n",
    "z = torch.randn(1, z_size)\n",
    "g_im = G(z)\n",
    "\n",
    "# Display.\n",
    "disp_img = out2img(g_im.detach().numpy().squeeze())\n",
    "print(\"Image size: {}x{}\".format(disp_img.shape[0], disp_img.shape[1]))\n",
    "plt.figure(figsize=(2, 2))  \n",
    "plt.axis('off')\n",
    "plt.imshow(disp_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Define a Descriminator (D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriminator architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/networkD.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, 32, 4, stride = 2, padding=1),\n",
    "                                   nn.LeakyReLU(0.2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(32, 64, 4, stride = 2, padding=1),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.LeakyReLU(0.2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64, 128, 3, stride = 2, padding=1),\n",
    "                                   nn.BatchNorm2d(128),\n",
    "                                   nn.LeakyReLU(0.2))\n",
    "        self.fc = nn.Linear(128*4*4, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the GPU.\n"
     ]
    }
   ],
   "source": [
    "# Check for CUDA\n",
    "use_cuda = False\n",
    "if torch.cuda.is_available(): \n",
    "    use_cuda = True\n",
    "    print(\"Using the GPU.\")\n",
    "else:\n",
    "    print(\"Cuda is not availabe, using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_loss(pred):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    expected_output = torch.ones(pred.shape[0], 1)\n",
    "    if use_cuda:\n",
    "        expected_output = expected_output.cuda()\n",
    "    return criterion(pred, expected_output)\n",
    "\n",
    "def fake_loss(pred):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    expected_output = torch.zeros(pred.shape[0], 1)\n",
    "    if use_cuda:\n",
    "        expected_output = expected_output.cuda()\n",
    "    return criterion(pred, expected_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate num_imgs x h x w tensor into a single image.\n",
    "def concat_imgs(np_imgs): \n",
    "    num_imgs = np_imgs.shape[0]\n",
    "    h = np_imgs.shape[1]\n",
    "    w = np_imgs.shape[2]\n",
    "    out = np.zeros((h, num_imgs*w))\n",
    "    for i in range(num_imgs):\n",
    "        out[:, i*w:(i+1)*w] = np_imgs[i,:,:]\n",
    "    return out        \n",
    "\n",
    "\n",
    "def train_GAN(G, D, optimizer_g, optimizer_d, input_size, batch_size = 32, num_epochs = 30):\n",
    "    sample_size = 10\n",
    "    z_fixed = torch.randn(sample_size, input_size)\n",
    "    if use_cuda:\n",
    "        z_fixed = z_fixed.cuda()\n",
    "        \n",
    "    # GET THE DATA\n",
    "    mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "    data_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size = batch_size, shuffle= True)\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        d_losses = 0.0\n",
    "        g_losses = 0.0        \n",
    "        # Iterate over the dataset.\n",
    "        for ii, (real_imgs, _) in enumerate(data_loader):\n",
    "            # Bring the input image pixels between -1 and 1\n",
    "            real_imgs = img2inp(real_imgs)   \n",
    "            if use_cuda:\n",
    "                real_imgs = real_imgs.cuda()\n",
    "                \n",
    "            # ======== TRAIN DESCRIMNATOR ===============\n",
    "            optimizer_d.zero_grad()\n",
    "            \n",
    "            pred = D(real_imgs)\n",
    "            # D should learns to predict real image as real, i.e., label 1\n",
    "            real_loss_d = real_loss(pred)\n",
    "            \n",
    "            # Create fake examples.\n",
    "            z = torch.randn(batch_size, input_size)\n",
    "            if use_cuda:\n",
    "                z = z.cuda()\n",
    "            fake_imgs = G(z)    \n",
    "            pred = D(fake_imgs.detach())\n",
    "            # D should learns to predict the generated images as fake, i.e., label 0\n",
    "            fake_loss_d = fake_loss(pred) \n",
    "            \n",
    "            # Descriminator opt takes a step.\n",
    "            total_loss_d = real_loss_d + fake_loss_d\n",
    "            total_loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            # ============= TRAIN GENERATOR =============\n",
    "            optimizer_g.zero_grad()\n",
    "            # Create more fake examples.\n",
    "            z = torch.randn(batch_size, input_size) \n",
    "            if use_cuda:\n",
    "                z = z.cuda()\n",
    "            fake_imgs = G(z)\n",
    "            pred = D(fake_imgs)     \n",
    "            # G tries to learn such that generated images pass as real.\n",
    "            loss_g = real_loss(pred) \n",
    "            loss_g.backward()\n",
    "            optimizer_g.step()\n",
    "            \n",
    "            # Save losses\n",
    "            d_losses += total_loss_d.detach().cpu().item()\n",
    "            g_losses += loss_g.detach().cpu().item()\n",
    "            \n",
    "            sys.stdout.write(\"\\r Processing: {}/{}...\".format(ii+1, len(data_loader)))\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        d_loss_epoch = d_losses/len(data_loader)\n",
    "        g_loss_epoch = g_losses/len(data_loader)\n",
    "        print(\"Epoch: {}, D loss: {}, G loss: {}\".format(e, d_loss_epoch, g_loss_epoch))\n",
    "        \n",
    "        # Save a few images as example.\n",
    "        G.eval()\n",
    "        out_imgs = G(z_fixed)\n",
    "        out_imgs = out2img(out_imgs) # Convert to right size.\n",
    "        disp_imgs = np.squeeze(out_imgs.detach().cpu().numpy())\n",
    "        combined_img = concat_imgs(disp_imgs)*255\n",
    "        combined_img = combined_img.astype(np.uint8)\n",
    "        img_to_save = Image.fromarray(combined_img)\n",
    "        img_to_save.save(\"./data/sample_output{}.png\".format(e))\n",
    "        \n",
    "        # Save the checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': e + 1,\n",
    "            'state_dict': G.state_dict()         \n",
    "        }\n",
    "        torch.save(checkpoint, 'checkpoint.pth')\n",
    "        G.train()\n",
    "    print(\"Done training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model from file...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "G = Generator(z_size)\n",
    "D = Discriminator()\n",
    "if use_cuda:\n",
    "    G = G.cuda()\n",
    "    D = D.cuda()\n",
    "\n",
    "if os.path.exists('checkpoint.pth'):\n",
    "    print(\"Loading trained model from file...\")\n",
    "    G.load_state_dict(torch.load('checkpoint.pth')[\"state_dict\"])\n",
    "else:\n",
    "    print(\"Training...\")\n",
    "    # Train your own model.\n",
    "    lr = 0.0001\n",
    "    beta1 = 0.5\n",
    "    beta2 = 0.999\n",
    "\n",
    "    optimg = torch.optim.Adam(G.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "    optimd = torch.optim.Adam(D.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "    train_GAN(G, D, optimg, optimd, z_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample image:  epoch 01\n",
    "<img src=\"./imgs/sample_output0.png\" width=\"800\">\n",
    "\n",
    "#### Sample images: epoch 30\n",
    "<img src=\"./imgs/sample_output29.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Generate new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "G.eval()\n",
    "z = torch.randn(1, z_size)\n",
    "if use_cuda:\n",
    "    z = z.cuda()\n",
    "G_out = G(z)\n",
    "img = np.squeeze(G_out.detach().cpu().numpy())\n",
    "\n",
    "plt.figure(figsize=(2, 2))  \n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. Wonderful animations of convolution arithmatic: https://github.com/vdumoulin/conv_arithmetic\n",
    "2. A more detailed GAN example from torch developes: https://github.com/pytorch/examples/tree/master/dcgan\n",
    "3. How to train a GAN: tips and tricks: https://github.com/soumith/ganhacks\n",
    "4. NN_SVG- An online tool for generating network diagrams: http://alexlenail.me/NN-SVG/AlexNet.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
